---
layout: post
status: publish
published: true
title: Acceptance testing a pyglet application
author:
  display_name: tartley
  login: tartley
  email: tartley@tartley.com
  url: http://tartley.com
author_login: tartley
author_email: tartley@tartley.com
author_url: http://tartley.com
wordpress_id: 353
wordpress_url: http://www.tartley.com/?p=353
date: '2008-07-04 17:30:58 -0500'
date_gmt: '2008-07-04 17:30:58 -0500'
categories:
- Python
- Testing
- Graphics
tags: []
comments:
- id: 30951
  author: mac
  author_email: mac@multikultis.com
  author_url: http://multikultis.com
  date: '2010-08-01 17:19:16 -0500'
  date_gmt: '2010-08-01 16:19:16 -0500'
  content: "Awesome, precisely what I was waiting for. I am off to try it! (Me too
    had no joy with the threads, this is how I googled and found this post).\r\n\r\nI
    noticed however that this post is rather old. I was wondering if you had further
    refined this idea, or if you found out any other way to do testing for pyglet
    apps..."
- id: 31006
  author: tartley
  author_email: tartley@tartley.com
  author_url: http://tartley.com
  date: '2010-08-02 09:41:03 -0500'
  date_gmt: '2010-08-02 08:41:03 -0500'
  content: "Thanks mac. I haven't refined the idea since then - in the end, I found
    that even with this sort of framework, adding extra system-level testing to game-like
    OpenGL applications to be quite difficult (since I was thinking about trying to
    analyse the appearance of what gets rendered on screen)\r\n\r\nSo the ideas described
    here have been invaluable to serve as a smoke-test, to run one or two simple system-level
    tests as shown, especially to run them on an install (rather then from source),
    to check that everything still works after being bundled up and then installed
    on various operating systems.\r\n\r\nIf you do have any better ideas about what
    sort of things it makes sense to system-test in an OpenGL application, I'd be
    all ears. Perhaps I'm having problems because I'm trying to test it at the wrong
    level of abstraction."
- id: 31015
  author: mac
  author_email: mac@multikultis.com
  author_url: http://multikultis.com
  date: '2010-08-02 12:52:51 -0500'
  date_gmt: '2010-08-02 11:52:51 -0500'
  content: "Although I am not new to Python, the one I am working on is my very first
    OpenGL application. At the end I settled down for the following solution:\r\n\r\nhttp://pastebin.com/Een75nWZ\r\n\r\nThe
    basic idea is that: \r\n1) Your test suite will schedule \"run_next_test\" in
    the main application scheduler at regular interval.\r\n2) Tests are kept in a
    circular buffer\r\n3) Tests can fail, succeed or be postponed (if the environment
    is still not ripe to perform the test.\r\n4) Test have full access to the window
    object, so they can test any propriety of the entities or trigger any of their
    methods.\r\n\r\nMine - like yours - is just a stub. It works for the kind of tests
    I want to perform right now, but it has a few limitations. Most notably:\r\n-
    I am not using the standard \"unittest\" (= my own test grammar)\r\n- Tests are
    scheduled at regular intervals rather than been triggered by a specific condition.\r\n\r\nBoth
    of them - though - could be circumvented with some extra work.\r\n\r\nPS: Your
    blog is the best learning aid I could find on the intertubes for somebody - like
    me - new to pyglet. Thanks!"
---
<p>I've been trying to create a simple acceptance test for a <a href="http://pyglet.org/">pyglet </a>application. A thorough suite of acceptance tests, verifying the correctness of all the shapes drawn to the screen by OpenGL, sounds like far more work than I want to do. But a couple of simple acceptance tests would be valuable, to check out basic things: that the application runs; opens a fullscreen window; responds correctly to some basic inputs and command-line options; and has an acceptable framerate. Especially if I could quickly run this basic smoke test on multiple operating systems.</p>
<p>I tried writing an acceptance test which ran the application-under-test on a new thread. This didn't work for me *at all* (perhaps because pyglet is not intended to be used with multiple threads), so for the time being I'd given up, and was proceeding without acceptance-level tests.</p>
<p>A couple of days ago I had the idea of a test that didn't involve threading. Instead, it takes a list of test conditions (as lambdas), and uses pyglet's own clock and scheduler to request a callback to a test function - <code>try_condition()</code> - on every frame:</p>
<pre class="prettyprint">    def try_condition(self, dt):
        if self.condition():
            self.next_condition()
        else:
            self.time += dt
            if self.time > self.timeout:
                self.fail("timeout on %s" % self.condition)</pre>
<p>When <code>try_condition()</code> gets called by pyglet on the first frame, it  evaluates the value of <code>self.condition</code>. If <code>True</code>, then that first part of the test has passed, and it gets the next condition off the list. If <code>False</code>, then this function simply returns, to let the application continue running. When <code>try_condition()</code> is called again on the next frame, it resumes where it left off, testing out the same condition again. After it has been trying the same condition for a long enough time, it deems that condition to have failed, and raises an assertion error.</p>
<p>Here is the rest of the class, which sets up the scheduled calls to <code>try_condition()</code>.</p>
<pre class="prettyprint">from unittest import TestCase
from pyglet import app, clock

class AcceptanceTest(TestCase):

    timeout = 1.0

    def set_conditions(self, conditions):
        self.conditions = conditions
        self.next_condition()
        clock.schedule(lambda dt: self.try_condition(dt))</pre>
<p>So <code>self.conditions</code> is a list of lambdas that will be provided by the acceptance test. Calling <code>self.next_condition()</code> merely plucks the next condition off the list, into <code>self.condition</code>. If there are no more conditions left, then the test has entirely passed and it requests the application to terminate, by setting the pyglet member <code>window.has_exit</code> to <code>True</code>.</p>
<pre class="prettyprint">    def next_condition(self):
        if len(self.conditions) > 0:
            self.condition = self.conditions.pop(0)
            self.time = 0.0
        else:
            self.terminate()

    def terminate(self):
        win = self.get_window()
        win.has_exit = True

    def get_window(self):
        windows = self.get_windows()
        if len(windows) == 1:
            return windows[0]
        return None

    def get_windows(self):
        return [w for w in app.windows]</pre>
<p>In future, I should probably allow the acceptance test code to specify a different timeout value for each condition.</p>
<p>Anyhow, we can then write an acceptance test by inheriting from this <code>AcceptanceTest</code> class, providing an appropriate list of conditions, and then just calling the application's <code>main()</code> function. This function won't return until the application exits, either when one of the conditions times out and raises an assertion error, or else when all conditions have passed and the test framework sets <code>window.has_exit</code>.</p>
<pre class="prettyprint">from testutils.testcase import run_test
from acceptance_test import AcceptanceTest
from sole_scion import main

class AT001_app_opens_a_fullscreen_window(AcceptanceTest):

    def is_window_visible(self):
        win = self.get_window()
        return win and win.visible

    def is_window_fullscreen(self):
        win = self.get_window()
        return win and win.fullscreen

    def test_window(self):
        conditions = [
            self.is_window_visible,
            self.is_window_fullscreen,
        ]
        self.set_conditions(conditions)
        main()

if __name__ == "__main__":
    run_test()</pre>
<p>The conditions don't simply have to be expressions to verify the application state. They could stimulate the application by raising mouse or keyboard events, etc, and then simply return <code>True</code> so that the test harness would move right on to the next condition.</p>
<p>Early days with this idea, but it seems to work, and thus far I'm very happy with it.</p>
